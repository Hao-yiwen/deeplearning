{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片扩散模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 469/469 [07:18<00:00,  1.07it/s, loss=0.0609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 469/469 [08:15<00:00,  1.06s/it, loss=0.0519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.0572\n",
      "生成最终样本...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"简单的U-Net结构作为去噪网络\"\"\"\n",
    "    def __init__(self, in_channels=1):  # 修改为1通道，因为MNIST是灰度图\n",
    "        super().__init__()\n",
    "        # 编码器\n",
    "        self.enc1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
    "        self.enc2 = nn.Conv2d(64, 128, 3, padding=1, stride=2)\n",
    "        self.enc3 = nn.Conv2d(128, 256, 3, padding=1, stride=2)\n",
    "        \n",
    "        # 时间嵌入处理\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "        )\n",
    "        \n",
    "        # 解码器\n",
    "        self.dec3 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(256, 64, 4, stride=2, padding=1)\n",
    "        self.dec1 = nn.Conv2d(128, in_channels, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x, time_emb):\n",
    "        # 编码过程\n",
    "        e1 = F.relu(self.enc1(x))\n",
    "        e2 = F.relu(self.enc2(e1))\n",
    "        e3 = F.relu(self.enc3(e2))\n",
    "        \n",
    "        # 处理时间嵌入\n",
    "        time_emb = self.time_mlp(time_emb)\n",
    "        time_emb = time_emb.view(-1, 256, 1, 1).repeat(1, 1, e3.shape[2], e3.shape[3])\n",
    "        e3 = e3 + time_emb\n",
    "        \n",
    "        # 解码过程(使用跳跃连接)\n",
    "        d3 = F.relu(self.dec3(e3))\n",
    "        d2 = F.relu(self.dec2(torch.cat([d3, e2], dim=1)))\n",
    "        d1 = self.dec1(torch.cat([d2, e1], dim=1))\n",
    "        return d1\n",
    "\n",
    "class DiffusionModel:\n",
    "    def __init__(self, timesteps=1000):\n",
    "        self.timesteps = timesteps\n",
    "        # 定义噪声调度\n",
    "        self.beta = torch.linspace(1e-4, 0.02, timesteps)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        \n",
    "        # 初始化去噪网络\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.denoise_model = SimpleUNet().to(self.device)\n",
    "        self.optimizer = optim.Adam(self.denoise_model.parameters(), lr=1e-4)\n",
    "        \n",
    "    def time_embedding(self, timesteps, dim=256):\n",
    "        \"\"\"生成时间步的嵌入向量\"\"\"\n",
    "        half = dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -torch.log(torch.tensor(10000.0)) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
    "        ).to(self.device)\n",
    "        args = timesteps[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        return embedding\n",
    "\n",
    "    def add_noise(self, x_0, t):\n",
    "        \"\"\"给图像添加噪声\"\"\"\n",
    "        eps = torch.randn_like(x_0)\n",
    "        alpha_bar_t = self.alpha_bar[t].to(self.device)\n",
    "        noisy = torch.sqrt(alpha_bar_t)[:, None, None, None] * x_0 + \\\n",
    "                torch.sqrt(1 - alpha_bar_t)[:, None, None, None] * eps\n",
    "        return noisy, eps\n",
    "    \n",
    "    def train_step(self, x_0):\n",
    "        \"\"\"单个训练步骤\"\"\"\n",
    "        batch_size = x_0.shape[0]\n",
    "        \n",
    "        # 随机采样时间步\n",
    "        t = torch.randint(0, self.timesteps, (batch_size,)).to(self.device)\n",
    "        \n",
    "        # 添加噪声\n",
    "        noisy_images, noise = self.add_noise(x_0, t)\n",
    "        \n",
    "        # 预测噪声\n",
    "        time_emb = self.time_embedding(t)\n",
    "        predicted_noise = self.denoise_model(noisy_images, time_emb)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = F.mse_loss(predicted_noise, noise)\n",
    "        \n",
    "        # 反向传播\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def train(self, dataloader, epochs):\n",
    "        \"\"\"训练过程\"\"\"\n",
    "        self.denoise_model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            with tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}') as pbar:\n",
    "                for batch in pbar:\n",
    "                    images, _ = batch\n",
    "                    images = images.to(self.device)\n",
    "                    loss = self.train_step(images)\n",
    "                    total_loss += loss\n",
    "                    pbar.set_postfix({'loss': loss})\n",
    "            \n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "            \n",
    "            # 每个epoch结束后生成一个示例\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                self.generate_samples(epoch + 1)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, img_size=32):\n",
    "        \"\"\"生成图像采样过程\"\"\"\n",
    "        self.denoise_model.eval()\n",
    "        x = torch.randn(batch_size, 1, img_size, img_size).to(self.device)\n",
    "        \n",
    "        for t in reversed(range(self.timesteps)):\n",
    "            t_batch = torch.full((batch_size,), t, dtype=torch.long).to(self.device)\n",
    "            time_emb = self.time_embedding(t_batch)\n",
    "            predicted_noise = self.denoise_model(x, time_emb)\n",
    "            \n",
    "            alpha_t = self.alpha[t].to(self.device)\n",
    "            alpha_bar_t = self.alpha_bar[t].to(self.device)\n",
    "            beta_t = self.beta[t].to(self.device)\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = 0\n",
    "                \n",
    "            x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * predicted_noise) + \\\n",
    "                torch.sqrt(beta_t) * noise\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def generate_samples(self, epoch, num_samples=5):\n",
    "        \"\"\"生成示例图像并保存\"\"\"\n",
    "        samples = self.sample(batch_size=num_samples)\n",
    "        samples = samples.cpu()\n",
    "        \n",
    "        # 创建图像网格\n",
    "        fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "        for i, sample in enumerate(samples):\n",
    "            axes[i].imshow(sample.squeeze(), cmap='gray')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Generated Samples at Epoch {epoch}')\n",
    "        plt.savefig(f'samples_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "def load_mnist_data(batch_size=64):\n",
    "    \"\"\"加载MNIST数据集\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.MNIST(root='./data', train=True, \n",
    "                           download=True, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def main():\n",
    "    # 设置随机种子\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # 创建模型和数据加载器\n",
    "    diffusion = DiffusionModel(timesteps=1000)\n",
    "    dataloader = load_mnist_data(batch_size=128)\n",
    "    \n",
    "    # 训练模型\n",
    "    print(\"开始训练...\")\n",
    "    diffusion.train(dataloader, epochs=2)\n",
    "    \n",
    "    # 保存模型\n",
    "    torch.save(diffusion.denoise_model.state_dict(), 'diffusion_model.pth')\n",
    "    \n",
    "    # 生成最终样本\n",
    "    print(\"生成最终样本...\")\n",
    "    samples = diffusion.sample(batch_size=10)\n",
    "    \n",
    "    # 显示生成的样本\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, sample in enumerate(samples):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(sample.cpu().squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig('final_samples.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
