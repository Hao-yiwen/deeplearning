{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3603\n",
      "Epoch 100, Loss: 0.0473\n",
      "Epoch 200, Loss: 0.0060\n",
      "Epoch 300, Loss: 0.0007\n",
      "Epoch 400, Loss: 0.0001\n",
      "Epoch 500, Loss: 0.0000\n",
      "Epoch 600, Loss: 0.0000\n",
      "Epoch 700, Loss: 0.0000\n",
      "Epoch 800, Loss: 0.0000\n",
      "Epoch 900, Loss: 0.0000\n",
      "\n",
      "训练完成:\n",
      "预测输出: [[0.59998252]]\n",
      "目标值: [0.6]\n",
      "最终损失: 3.055896246576464e-10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleRNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # 初始化权重\n",
    "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01   # 输入层到隐藏层的权重\n",
    "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # 隐藏层到隐藏层的权重\n",
    "        self.Why = np.random.randn(output_size, hidden_size) * 0.01  # 隐藏层到输出层的权重\n",
    "        \n",
    "        # 初始化偏置\n",
    "        self.bh = np.zeros((hidden_size, 1))  # 隐藏层偏置\n",
    "        self.by = np.zeros((output_size, 1))  # 输出层偏置\n",
    "        \n",
    "    def forward(self, inputs, hidden_state):\n",
    "        # 输入: inputs是一个序列，hidden_state是隐藏状态\n",
    "        self.inputs = inputs\n",
    "        self.hidden_states = []\n",
    "        h = hidden_state\n",
    "        \n",
    "        # 前向传播过程\n",
    "        for x in inputs:\n",
    "            # 重塑输入为列向量\n",
    "            x = x.reshape(-1, 1)\n",
    "            \n",
    "            # 计算隐藏状态\n",
    "            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)\n",
    "            self.hidden_states.append(h)\n",
    "        \n",
    "        # 计算输出\n",
    "        y = np.dot(self.Why, h) + self.by\n",
    "        \n",
    "        return y, h\n",
    "    \n",
    "    def backward(self, target, learning_rate=0.01):\n",
    "        # 初始化梯度\n",
    "        dWxh = np.zeros_like(self.Wxh)\n",
    "        dWhh = np.zeros_like(self.Whh)\n",
    "        dWhy = np.zeros_like(self.Why)\n",
    "        dbh = np.zeros_like(self.bh)\n",
    "        dby = np.zeros_like(self.by)\n",
    "        \n",
    "        # 获取最后的隐藏状态\n",
    "        h = self.hidden_states[-1]\n",
    "        \n",
    "        # 计算输出层的误差\n",
    "        # 均方损失函数中，损失函数对输出的导数是输出-目标值\n",
    "        dy = self.output - target\n",
    "        \n",
    "        # 计算Why的梯度\n",
    "        dWhy += np.dot(dy, h.T)\n",
    "        dby += dy\n",
    "        \n",
    "        # 反向传播通过时间\n",
    "        dh_next = np.zeros_like(h)\n",
    "        \n",
    "        for t in reversed(range(len(self.inputs))):\n",
    "            # 当前时间步的隐藏状态\n",
    "            h = self.hidden_states[t]\n",
    "            \n",
    "            # 计算隐藏层的梯度\n",
    "            dh = np.dot(self.Why.T, dy) + dh_next\n",
    "            \n",
    "            # 计算tanh的导数\n",
    "            dtanh = (1 - h * h) * dh\n",
    "            \n",
    "            # 计算各个权重的梯度\n",
    "            dbh += dtanh\n",
    "            dWxh += np.dot(dtanh, self.inputs[t].reshape(1, -1))\n",
    "            dWhh += np.dot(dtanh, self.hidden_states[t-1].T) if t > 0 else 0\n",
    "            \n",
    "            # 计算传递给下一个时间步的梯度\n",
    "            dh_next = np.dot(self.Whh.T, dtanh)\n",
    "        \n",
    "        # 更新权重和偏置\n",
    "        self.Wxh -= learning_rate * dWxh\n",
    "        self.Whh -= learning_rate * dWhh\n",
    "        self.Why -= learning_rate * dWhy\n",
    "        self.bh -= learning_rate * dbh\n",
    "        self.by -= learning_rate * dby\n",
    "\n",
    "def main():\n",
    "    # 创建训练数据\n",
    "    sequence = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    target = np.array([0.6])\n",
    "    \n",
    "    # 初始化RNN\n",
    "    rnn = SimpleRNN(input_size=1, hidden_size=8, output_size=1)\n",
    "    \n",
    "    # 训练参数\n",
    "    epochs = 1000\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(epochs):\n",
    "        # 初始化隐藏状态\n",
    "        hidden_state = np.zeros((8, 1))\n",
    "        \n",
    "        # 前向传播\n",
    "        output, final_hidden = rnn.forward(sequence, hidden_state)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = np.mean((output - target) ** 2)\n",
    "        \n",
    "        # 存储输出用于反向传播\n",
    "        rnn.output = output\n",
    "        \n",
    "        # 反向传播\n",
    "        rnn.backward(target, learning_rate)\n",
    "        \n",
    "        # 每100个epoch打印一次损失\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "    \n",
    "    # 训练结束后进行预测\n",
    "    hidden_state = np.zeros((8, 1))\n",
    "    final_output, _ = rnn.forward(sequence, hidden_state)\n",
    "    print(\"\\n训练完成:\")\n",
    "    print(\"预测输出:\", final_output)\n",
    "    print(\"目标值:\", target)\n",
    "    print(\"最终损失:\", np.mean((final_output - target) ** 2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
