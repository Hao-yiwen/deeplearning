{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a132fef2",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9caac-ccca-430b-91a4-571f2afcb306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置代理\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['no_proxy'] = '127.0.0.1,localhost'\n",
    "os.environ['NO_PROXY'] = '127.0.0.1,localhost'\n",
    "\n",
    "# 验证代理设置\n",
    "print(f\"HTTP代理: {os.environ.get('http_proxy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa486bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38422e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # torch.cat((p1, p2, p3, p4), dim=1) 是在dim=1（通道维度）拼接各个分支的输出，常用于通道上拼接不同特征图（如Inception结构所需）\n",
    "        # torch.stack((p1, p2, p3, p4), dim=1) 则是新建一个维度，将4个tensor在该新维度堆叠，结果shape比cat多1个维度（通常不是特征融合需要）\n",
    "        # 因此，这里应该继续使用cat而不是stack\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739414a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(\n",
    "    nn.Conv2d(64, 64, kernel_size=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = nn.Sequential(\n",
    "    Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "    Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "b5 = nn.Sequential(\n",
    "    Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "    Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "    nn.AdaptiveAvgPool2d((1,1)),\n",
    "    nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1008332",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d426a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里的1, 1分别代表批量大小和输入图片的通道数（例如黑白图像为1通道）\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65869bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理和加载 - 纯PyTorch实现\n",
    "# 为了适应AlexNet的输入尺寸(224x224),需要调整图像大小\n",
    "batch_size = 128\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(96),  # 调整图像大小到224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # 归一化\n",
    "])\n",
    "\n",
    "# 加载Fashion-MNIST数据集\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data',  # 数据存储路径\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_iter = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_iter = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'训练集大小: {len(train_dataset)}, 测试集大小: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7536ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数 - 纯PyTorch实现\n",
    "def train(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    print(f'training on {device}')\n",
    "    net.to(device)\n",
    "    \n",
    "    # 定义优化器和损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模式\n",
    "        net.train()\n",
    "        train_loss_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 统计\n",
    "            train_loss_sum += loss.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        \n",
    "        # 评估模式\n",
    "        test_acc = evaluate_accuracy(net, test_iter, device)\n",
    "        \n",
    "        print(f'epoch {epoch + 1}, loss {train_loss_sum / batch_count:.4f}, '\n",
    "              f'train acc {train_acc_sum / n:.3f}, test acc {test_acc:.3f}, '\n",
    "              f'time {time.time() - start:.1f} sec')\n",
    "\n",
    "def evaluate_accuracy(net, data_iter, device):\n",
    "    \"\"\"评估模型准确率\"\"\"\n",
    "    net.eval()\n",
    "    acc_sum, n = 0.0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            acc_sum += (net(X).argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    \n",
    "    return acc_sum / n\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 训练参数\n",
    "lr, num_epochs = 0.1, 10\n",
    "\n",
    "# 开始训练\n",
    "train(net, train_iter, test_iter, num_epochs, lr, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43485406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9cff07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
