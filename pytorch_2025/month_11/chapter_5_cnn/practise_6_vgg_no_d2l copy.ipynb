{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a132fef2",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a9caac-ccca-430b-91a4-571f2afcb306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP代理: http://127.0.0.1:7893\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 设置代理\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['no_proxy'] = '127.0.0.1,localhost'\n",
    "os.environ['NO_PROXY'] = '127.0.0.1,localhost'\n",
    "\n",
    "# 验证代理设置\n",
    "print(f\"HTTP代理: {os.environ.get('http_proxy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa486bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pa6e9jz8fp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置matplotlib - 适用于Linux服务器环境\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # 使用非交互式后端，适合服务器环境\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Linux服务器中文字体配置\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')\n",
    "\n",
    "# 尝试使用系统中文字体，如果没有则使用默认字体\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 'Droid Sans Fallback', 'SimHei', 'DejaVu Sans']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    print(\"中文字体配置完成\")\n",
    "except:\n",
    "    print(\"使用默认字体\")\n",
    "    \n",
    "# 清除matplotlib字体缓存\n",
    "import matplotlib.font_manager as fm\n",
    "fm._load_fontmanager(try_read_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3579547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38422e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1,64), (1,128),(2,256), (2,512), (2,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    conv_blocks = []\n",
    "    in_channel = 1\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blocks.append(vgg_block(num_convs=num_convs, in_channels=in_channel, out_channels=out_channels))\n",
    "        in_channel = out_channels\n",
    "        \n",
    "    return nn.Sequential(\n",
    "        *conv_blocks,\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(out_channels*7*7, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 10)\n",
    "    )\n",
    "    \n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d426a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 48, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 48, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 48, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 128, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 128, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 128, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 177, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 177, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 177, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 177, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 128, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 128, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 128, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 3200])\n",
      "Linear output shape:\t torch.Size([1, 2048])\n",
      "ReLU output shape:\t torch.Size([1, 2048])\n",
      "Dropout output shape:\t torch.Size([1, 2048])\n",
      "Linear output shape:\t torch.Size([1, 2048])\n",
      "ReLU output shape:\t torch.Size([1, 2048])\n",
      "Dropout output shape:\t torch.Size([1, 2048])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1,1,224,224)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, \" out shape:\\t\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65869bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 60000, 测试集大小: 10000\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理和加载 - 纯PyTorch实现\n",
    "# 为了适应AlexNet的输入尺寸(224x224),需要调整图像大小\n",
    "batch_size = 128\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # 调整图像大小到224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # 归一化\n",
    "])\n",
    "\n",
    "# 加载Fashion-MNIST数据集\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data',  # 数据存储路径\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_iter = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_iter = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'训练集大小: {len(train_dataset)}, 测试集大小: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7536ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "epoch 1, loss 2.3012, train acc 0.123, test acc 0.265, time 14.2 sec\n",
      "epoch 2, loss 2.1908, train acc 0.271, test acc 0.547, time 14.3 sec\n",
      "epoch 3, loss 0.8539, train acc 0.677, test acc 0.751, time 14.1 sec\n",
      "epoch 4, loss 0.6569, train acc 0.753, test acc 0.767, time 13.9 sec\n",
      "epoch 5, loss 0.5789, train acc 0.782, test acc 0.798, time 14.1 sec\n",
      "epoch 6, loss 0.5285, train acc 0.801, test acc 0.815, time 14.3 sec\n",
      "epoch 7, loss 0.4928, train acc 0.814, test acc 0.824, time 14.3 sec\n",
      "epoch 8, loss 0.4610, train acc 0.827, test acc 0.828, time 14.0 sec\n",
      "epoch 9, loss 0.4381, train acc 0.837, test acc 0.844, time 14.2 sec\n",
      "epoch 10, loss 0.4168, train acc 0.844, test acc 0.847, time 14.3 sec\n"
     ]
    }
   ],
   "source": [
    "# 训练函数 - 纯PyTorch实现\n",
    "def train(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print(f'training on {device}')\n",
    "    net.to(device)\n",
    "    \n",
    "    # 定义优化器和损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模式\n",
    "        net.train()\n",
    "        train_loss_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 统计\n",
    "            train_loss_sum += loss.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        \n",
    "        # 评估模式\n",
    "        test_acc = evaluate_accuracy(net, test_iter, device)\n",
    "        \n",
    "        print(f'epoch {epoch + 1}, loss {train_loss_sum / batch_count:.4f}, '\n",
    "              f'train acc {train_acc_sum / n:.3f}, test acc {test_acc:.3f}, '\n",
    "              f'time {time.time() - start:.1f} sec')\n",
    "\n",
    "def evaluate_accuracy(net, data_iter, device):\n",
    "    \"\"\"评估模型准确率\"\"\"\n",
    "    net.eval()\n",
    "    acc_sum, n = 0.0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            acc_sum += (net(X).argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    \n",
    "    return acc_sum / n\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 训练参数\n",
    "lr, num_epochs = 0.01, 10\n",
    "\n",
    "# 开始训练\n",
    "train(net, train_iter, test_iter, num_epochs, lr, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43485406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
