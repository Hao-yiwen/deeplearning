{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b47bc2c",
   "metadata": {},
   "source": [
    "# 全卷机网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b953038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff094b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC颜色映射\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "\n",
    "# 辅助函数\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    \"\"\"Set the figure size for matplotlib.\"\"\"\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"返回所有可用的GPU设备，如果没有GPU则返回[cpu()]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes]\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置matplotlib的轴\"\"\"\n",
    "        axes.set_xlabel(xlabel)\n",
    "        axes.set_ylabel(ylabel)\n",
    "        axes.set_xscale(xscale)\n",
    "        axes.set_yscale(yscale)\n",
    "        axes.set_xlim(xlim)\n",
    "        axes.set_ylim(ylim)\n",
    "        if legend:\n",
    "            axes.legend(legend)\n",
    "        axes.grid()\n",
    "\n",
    "    def add(self, x, y):\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().cpu().numpy()\n",
    "            if img.ndim == 3 and img.shape[0] in [1, 3]:\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "            if img.shape[-1] == 1:\n",
    "                img = img.squeeze(-1)\n",
    "        ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes\n",
    "\n",
    "def read_voc_images(voc_dir, is_train=True):\n",
    "    \"\"\"读取VOC图像和标签\"\"\"\n",
    "    txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation', 'train.txt' if is_train else 'val.txt')\n",
    "    mode = torchvision.io.image.ImageReadMode.RGB\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    features, labels = [], []\n",
    "    for i, fname in enumerate(images):\n",
    "        features.append(torchvision.io.read_image(os.path.join(\n",
    "            voc_dir, 'JPEGImages', f'{fname}.jpg'\n",
    "        )))\n",
    "        labels.append(torchvision.io.read_image(os.path.join(\n",
    "            voc_dir, 'SegmentationClass', f'{fname}.png'), mode))\n",
    "    return features, labels\n",
    "\n",
    "def voc_colormap2label():\n",
    "    \"\"\"构建从RGB到VOC类别索引的映射\"\"\"\n",
    "    colormap2label = torch.zeros(256 ** 3, dtype=torch.long)\n",
    "    for i, colormap in enumerate(VOC_COLORMAP):\n",
    "        colormap2label[\n",
    "            (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n",
    "    return colormap2label\n",
    "\n",
    "def voc_label_indices(colormap, colormap2label):\n",
    "    \"\"\"将VOC标签中的RGB值映射到它们的类别索引\"\"\"\n",
    "    colormap = colormap.permute(1, 2, 0).numpy().astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]\n",
    "\n",
    "def voc_rand_crop(feature, label, height, width):\n",
    "    \"\"\"随机裁剪特征和标签图像\"\"\"\n",
    "    rect = torchvision.transforms.RandomCrop.get_params(\n",
    "        feature, (height, width)\n",
    "    )\n",
    "    feature = torchvision.transforms.functional.crop(feature, *rect)\n",
    "    label = torchvision.transforms.functional.crop(label, *rect)\n",
    "    return feature, label\n",
    "\n",
    "class VOCSegDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"一个用于加载VOC数据集的自定义数据集\"\"\"\n",
    "    def __init__(self, is_train, crop_size, voc_dir):\n",
    "        self.transform = torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        self.crop_size = crop_size\n",
    "        features, labels = read_voc_images(voc_dir, is_train=is_train)\n",
    "        self.features = [self.normalize_image(feature) for feature in self.filter(features)]\n",
    "        self.labels = self.filter(labels)\n",
    "        self.colormap2label = voc_colormap2label()\n",
    "        print('read ' + str(len(self.features)) + ' examples')\n",
    "\n",
    "    def normalize_image(self, img):\n",
    "        return self.transform(img.float() / 255)\n",
    "\n",
    "    def filter(self, imgs):\n",
    "        return [img for img in imgs if (\n",
    "            img.shape[1] >= self.crop_size[0] and\n",
    "            img.shape[2] >= self.crop_size[1]\n",
    "        )]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature, label = voc_rand_crop(self.features[idx], self.labels[idx], *self.crop_size)\n",
    "        return (feature, voc_label_indices(label, self.colormap2label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "def download(name, cache_dir='../data'):\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 DATA_HUB\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    \n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    \n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def download_extract(name, folder=None):\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    \n",
    "    if ext == '.zip':\n",
    "        with zipfile.ZipFile(fname, 'r') as fp:\n",
    "            fp.extractall(base_dir)\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        with tarfile.open(fname, 'r') as fp:\n",
    "            fp.extractall(base_dir)\n",
    "    \n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def load_data_voc(batch_size, crop_size):\n",
    "    \"\"\"加载VOC语义分割数据集\"\"\"\n",
    "    DATA_HUB['voc2012'] = (DATA_URL + 'VOCtrainval_11-May-2012.tar',\n",
    "                           '4e443f8a2eca6b1dac8a6c57641b67dd40621a49')\n",
    "    voc_dir = download_extract('voc2012', os.path.join('VOCdevkit', 'VOC2012'))\n",
    "    num_workers = 0\n",
    "    train_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(True, crop_size, voc_dir), batch_size,\n",
    "        shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(False, crop_size, voc_dir), batch_size,\n",
    "        drop_last=True, num_workers=num_workers)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "        if device is None:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    metric = [0.0] * 2\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric[0] += (net(X).argmax(dim=1) == y).sum().item()\n",
    "            metric[1] += y.numel()\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def train_batch_ch13(net, X, y, loss, trainer, devices):\n",
    "    \"\"\"用多GPU进行小批量训练\"\"\"\n",
    "    if isinstance(X, list):\n",
    "        X = [x.to(devices[0]) for x in X]\n",
    "    else:\n",
    "        X = X.to(devices[0])\n",
    "    y = y.to(devices[0])\n",
    "    \n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    pred = net(X)\n",
    "    l = loss(pred, y)\n",
    "    l.mean().backward()\n",
    "    trainer.step()\n",
    "    \n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum\n",
    "\n",
    "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices=None):\n",
    "    \"\"\"用GPU训练模型（在第十三章定义）\"\"\"\n",
    "    if devices is None:\n",
    "        devices = try_all_gpus()\n",
    "    \n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
    "                       legend=['train loss', 'train acc', 'test acc'])\n",
    "    \n",
    "    if len(devices) > 1 and str(devices[0]).startswith('cuda'):\n",
    "        net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    else:\n",
    "        net = net.to(devices[0])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = train_batch_ch13(net, features, labels, loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0])\n",
    "            timer.stop()\n",
    "            \n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                           (metric[0] / metric[2], metric[1] / metric[2], None))\n",
    "        \n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    \n",
    "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
    "          f'{metric[1] / metric[2]:.3f}, test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
    "          f'{str(devices)}')\n",
    "\n",
    "pretrained_net = torchvision.models.resnet18(pretrained=True)\n",
    "list(pretrained_net.children())[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(*list(pretrained_net.children()))[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(size=(1,3,320,480))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 21\n",
    "net.add_module('final_conv', nn.Conv2d(512, num_classes, kernel_size=1))\n",
    "net.add_module('transpose_conv', nn.ConvTranspose2d(num_classes, num_classes, kernel_size=64, padding=16, stride=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该函数用于初始化上采样层的权重，使其表现为双线性插值的效果。\n",
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    # 计算插值的中心位置\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    # 生成一个二维网格，og[0]表示每行的索引，og[1]表示每列的索引\n",
    "    og = (torch.arange(kernel_size).reshape(-1, 1),\n",
    "          torch.arange(kernel_size).reshape(1, -1))\n",
    "    # 计算滤波器的权重，即双线性插值核\n",
    "    filt = (1 - torch.abs(og[0] - center) / factor) * \\\n",
    "           (1 - torch.abs(og[1] - center) / factor)\n",
    "    # 创建权重矩阵，并将双线性插值核复制到对角线上，每个通道使用相同的核\n",
    "    weight = torch.zeros((in_channels, out_channels,\n",
    "                          kernel_size, kernel_size))\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8734d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_trans = nn.ConvTranspose2d(3,3,kernel_size=4, padding=1, stride=2, bias=False)\n",
    "conv_trans.weight.data.copy_(bilinear_kernel(3,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c261e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.transforms.ToTensor()(Image.open('../img/catdog.jpg'))\n",
    "X = img.unsqueeze(0)\n",
    "Y = conv_trans(X)\n",
    "out_img = Y[0].permute(1, 2, 0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_figsize()\n",
    "print('input image shape:', img.permute(1, 2, 0).shape)\n",
    "plt.imshow(img.permute(1, 2, 0));\n",
    "print('output image shape:', out_img.shape)\n",
    "plt.imshow(out_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793146c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = bilinear_kernel(num_classes, num_classes, 64)\n",
    "net.transpose_conv.weight.data.copy_(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, crop_size = 32, (320, 480)\n",
    "train_iter, test_iter = load_data_voc(batch_size, crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d243844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(inputs, targets):\n",
    "    return F.cross_entropy(inputs, targets, reduction='none').mean(1).mean(1)\n",
    "\n",
    "num_epochs, lr, wd, devices = 5, 0.001, 1e-3, try_all_gpus()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd)\n",
    "train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    X = test_iter.dataset.normalize_image(img).unsqueeze(0)\n",
    "    pred = net(X.to(devices[0])).argmax(dim=1)\n",
    "    return pred.reshape(pred.shape[1], pred.shape[2])\n",
    "\n",
    "def label2image(pred):\n",
    "    colormap = torch.tensor(VOC_COLORMAP, device=devices[0])\n",
    "    X = pred.long()\n",
    "    return colormap[X, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB['voc2012'] = (DATA_URL + 'VOCtrainval_11-May-2012.tar',\n",
    "                       '4e443f8a2eca6b1dac8a6c57641b67dd40621a49')\n",
    "voc_dir = download_extract('voc2012', 'VOCdevkit/VOC2012')\n",
    "test_images, test_labels = read_voc_images(voc_dir, False)\n",
    "n, imgs = 4, []\n",
    "for i in range(4):\n",
    "    crop_rect = (0,0,320, 480)\n",
    "    X = torchvision.transforms.functional.crop(test_images[i], *crop_rect)\n",
    "    pred = label2image(predict(X))\n",
    "    imgs += [X.permute(1,2,0), pred.cpu(),\n",
    "             torchvision.transforms.functional.crop(\n",
    "                 test_labels[i], *crop_rect).permute(1,2,0)]\n",
    "show_images(imgs[::3] + imgs[1::3] + imgs[2::3], 3, n, scale=2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
