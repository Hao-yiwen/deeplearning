{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f43f8d4",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc0237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from d2l import torch as d2l\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546674f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads， num_hiddens/num_heads)\n",
    "    X= X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数, num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数, num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "#@save\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "class MultiHeaderAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, num_heads, dropout, bias=False) -> None:\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = d2l.DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "    \n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "        \n",
    "        if valid_lens is not None:\n",
    "            # 将 valid_lens 重复 num_heads 次，因为每个注意力头都需要独立的 valid_lens\n",
    "            # 注意：参数名是 repeats 而不是 repeat\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0\n",
    "            )\n",
    "        \n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        \n",
    "        output_cat = transpose_output(output, num_heads=self.num_heads)\n",
    "        return self.W_o(output_cat)\n",
    "\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, dropout) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs) -> None:\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "\n",
    "#@save\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        # 使用我们自己定义的 MultiHeaderAttention，而不是 d2l.MultiHeadAttention\n",
    "        # 因为 d2l.MultiHeadAttention 的签名可能不同\n",
    "        self.attention = MultiHeaderAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            bias=use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a1c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_and_segments(tokens_a, tokens_b):\n",
    "    tokens = ['<cls>'] + tokens_a + ['<seq>']\n",
    "    segments = [0] * (len(tokens_a) + 2)\n",
    "    if tokens_b is not None:\n",
    "        tokens += tokens_b + ['<seq>']\n",
    "        segments += [1] * (len(tokens_b) + 1)\n",
    "    return tokens, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffdeb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    BertEncoder\n",
    "    segment表示“句子片段类型embedding”。\n",
    "    在BERT中，输入通常是两段文本拼接，例如句子A和句子B。\n",
    "    segment用于区分不同的句子（例如A为0，B为1），以便模型能够知道某个token属于哪一部分。\n",
    "\n",
    "    输入是2，代表segment可以取两种类型（0或1）：0表示第一个句子片段，1表示第二个句子片段。\n",
    "    如果只输入单句任务，全部segment为0；如果是句子对任务，根据分割点设置为0和1。\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_lens = 1000, key_size=768, query_size=768, value_size=768) -> None:\n",
    "        super().__init__()\n",
    "        self.token_embeding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        # segment_embeding输入2，代表两种类型（句子1和句子2：0或1）\n",
    "        self.segment_embeding = nn.Embedding(2, num_hiddens)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f\"{i}\", EncoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                                                      ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))\n",
    "        # 位置编码，shape=[1, max_lens, num_hiddens]，可学习\n",
    "        self.pos_embeding = nn.Parameter(torch.randn(1, max_lens, num_hiddens))\n",
    "    \n",
    "    def forward(self, token, segment, valid_lens):\n",
    "        \"\"\"\n",
    "        token: 词索引序列，[batch, seq_len]\n",
    "        segment: 句子片段类型，[batch, seq_len]，值为0或1\n",
    "        valid_lens: 有效长度\n",
    "        \"\"\"\n",
    "        # token embedding + segment embedding\n",
    "        X = self.token_embeding(token) + self.segment_embeding(segment)\n",
    "        # 加上可学习的位置编码\n",
    "        X = X + self.pos_embeding.data[:, :X.shape[1], :]\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa82d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5456, -1.1562,  1.4382],\n",
      "        [-1.4969,  1.3885, -0.5923],\n",
      "        [-1.5456, -1.1562,  1.4382],\n",
      "        [-0.5804, -0.6946, -1.1193],\n",
      "        [-1.5456, -1.1562,  1.4382]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 会报错的原因：\n",
    "# nn.Embedding(2,3) 代表只能索引0或1（即num_embeddings=2，对应词表id只能是0/1），但x里有2，超出词表范围\n",
    "a = nn.Embedding(11, 3)\n",
    "x = torch.tensor([1, 10, 1, 2, 1])\n",
    "try:\n",
    "    out = a(x)\n",
    "    print(out)\n",
    "except Exception as e:\n",
    "    print(\"出错了:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935c9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4\n",
    "norm_shape, ffn_num_input, num_layers, dropout = [768], 768, 2, 0.2\n",
    "encoder = BertEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438afe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4586, 7666, 7013, 8943, 8274, 4586, 4618, 2260],\n",
      "        [5724,  561, 3460, 5897, 4056, 7071, 4400, 7349]])\n"
     ]
    }
   ],
   "source": [
    "tokens = torch.randint(0, vocab_size, (2,8))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef289752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoder_X = encoder(tokens, segments, None)\n",
    "encoder_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6fa96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLM(nn.Module):\n",
    "    def __init__(self, vocab_size, num_hiddens, num_inputs=768) -> None:\n",
    "        \"\"\"\n",
    "        Masked Language Model（MLM）模块。\n",
    "\n",
    "        参数说明：\n",
    "        vocab_size: 词表大小，输出类别数（即预测每个位置对应的词汇表token）。\n",
    "        num_hiddens: 隐藏层的维度。\n",
    "        num_inputs: 输入特征的维度，通常等于BERT编码器输出的隐藏单元数，默认768。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 构造一个MLP（多层感知机），输入num_inputs维，经过隐藏层后输出vocab_size维的预测。\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_inputs, num_hiddens), # 线性变换到隐藏层\n",
    "            nn.ReLU(),                          # 激活函数\n",
    "            nn.LayerNorm(num_hiddens),          # 层归一化\n",
    "            nn.Linear(num_hiddens, vocab_size)  # 映射到vocab_size，为softmax前的logits\n",
    "        )\n",
    "    \n",
    "    def forward(self, X, pred_positions):\n",
    "        \"\"\"\n",
    "        前向传播。\n",
    "\n",
    "        参数：\n",
    "        X: 经过BERT encoder后的表示，形状为 [batch_size, seq_len, hidden_dim]，\n",
    "           表示每个token的上下文表示。\n",
    "        pred_positions: 要预测的masked位置索引，形状为 [batch_size, num_pred_positions]，\n",
    "                        每行是一个样本要预测的位置列表。\n",
    "\n",
    "        返回：\n",
    "        mlm_Y_hat: 每个被mask位置的预测结果，\n",
    "                   形状为 [batch_size, num_pred_positions, vocab_size]。\n",
    "        \"\"\"\n",
    "        # 1. 得到每个样本需要预测的token数量\n",
    "        num_pred_positions = pred_positions.shape[1]\n",
    "        # 2. 将pred_positions展平为一维，便于统一索引\n",
    "        pred_positions_flat = pred_positions.reshape(-1)  # 长度为batch_size * num_pred_positions\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        # 3. 构造一个batch索引。例如batch_size=2, num_pred_positions=3时，得到[0,0,0,1,1,1]\n",
    "        batch_idx = torch.arange(0, batch_size).repeat_interleave(num_pred_positions)\n",
    "        # 这样(X[batch_idx, pred_positions_flat])就取出所有需要mask的token的表示\n",
    "\n",
    "        # 4. 按指定位置收集得到被mask位置的上下文表示，形状为 [batch_size * num_pred_positions, hidden_dim]\n",
    "        masked_X = X[batch_idx, pred_positions_flat]\n",
    "        # 5. 恢复成 [batch_size, num_pred_positions, hidden_dim] 的形式\n",
    "        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n",
    "\n",
    "        # 6. 通过MLP变换，每个位置最终输出vocab_size维，对应softmax前的logits\n",
    "        mlm_Y_hat = self.mlp(masked_X)\n",
    "\n",
    "        # 7. 输出，形状为 [batch_size, num_pred_positions, vocab_size]\n",
    "        return mlm_Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fb8b124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm = MaskLM(vocab_size, num_hiddens)\n",
    "mlm_postions = torch.tensor([[1,5,2],[6,1,5]])\n",
    "mlm_Y_hat = mlm(encoder_X, mlm_postions)\n",
    "mlm_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4214cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_Y = torch.tensor([[7,8,9], [10, 20, 30]])\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))\n",
    "mlm_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ce8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextSentencePred(nn.Module):\n",
    "    def __init__(self, num_inputs) -> None:\n",
    "        super().__init__()\n",
    "        self.output = nn.Linear(num_inputs, 2)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.output(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aace9ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_X = torch.flatten(encoder_X, start_dim=1)\n",
    "nsp = NextSentencePred(encoder_X.shape[-1])\n",
    "nsp_Y_hat = nsp(encoder_X)\n",
    "nsp_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9effa3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsp_y = torch.tensor([0, 1])\n",
    "nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "nsp_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba9581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BERTModel(nn.Module):\n",
    "    \"\"\"BERT模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_len=1000, key_size=768, query_size=768, value_size=768,\n",
    "                 hid_in_features=768, mlm_in_features=768,\n",
    "                 nsp_in_features=768):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.encoder = BertEncoder(vocab_size, num_hiddens, norm_shape,\n",
    "                    ffn_num_input, ffn_num_hiddens, num_heads, num_layers,\n",
    "                    dropout, max_len=max_len, key_size=key_size,\n",
    "                    query_size=query_size, value_size=value_size)\n",
    "        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),\n",
    "                                    nn.Tanh())\n",
    "        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)\n",
    "        self.nsp = NextSentencePred(nsp_in_features)\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens=None,\n",
    "                pred_positions=None):\n",
    "        encoded_X = self.encoder(tokens, segments, valid_lens)\n",
    "        if pred_positions is not None:\n",
    "            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n",
    "        else:\n",
    "            mlm_Y_hat = None\n",
    "        # 用于下一句预测的多层感知机分类器的隐藏层，0是“<cls>”标记的索引\n",
    "        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n",
    "        return encoded_X, mlm_Y_hat, nsp_Y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
