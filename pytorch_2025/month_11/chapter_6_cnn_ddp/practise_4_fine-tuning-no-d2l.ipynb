{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34074120",
   "metadata": {},
   "source": [
    "# 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c54791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置代理\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['no_proxy'] = '127.0.0.1,localhost'\n",
    "os.environ['NO_PROXY'] = '127.0.0.1,localhost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adeb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Defined in :numref:`sec_minibatch_sgd`\"\"\"\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "def try_gpu(i=0):\n",
    "    \"\"\"返回第i个GPU设备，如果不存在则返回CPU\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"返回所有可用的GPU设备，如果没有GPU则返回[cpu()]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = datasets.FashionMNIST(\n",
    "        root='./data', train=True, transform=trans, download=True)\n",
    "    mnist_test = datasets.FashionMNIST(\n",
    "        root='./data', train=False, transform=trans, download=True)\n",
    "    return (DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4),\n",
    "            DataLoader(mnist_test, batch_size, shuffle=False, num_workers=4))\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if device is None:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = [0.0] * 2\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric[0] += (net(X).argmax(dim=1) == y).sum().item()\n",
    "            metric[1] += y.numel()\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置matplotlib的轴\"\"\"\n",
    "        axes.set_xlabel(xlabel)\n",
    "        axes.set_ylabel(ylabel)\n",
    "        axes.set_xscale(xscale)\n",
    "        axes.set_yscale(yscale)\n",
    "        axes.set_xlim(xlim)\n",
    "        axes.set_ylim(ylim)\n",
    "        if legend:\n",
    "            axes.legend(legend)\n",
    "        axes.grid()\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "class Residual(nn.Module):\n",
    "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
    "                                   stride=strides)\n",
    "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    \"\"\"ResNet-18模型\"\"\"\n",
    "    def resnet_block(num_channels, num_residuals, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual(num_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    # ResNet-18\n",
    "    net = nn.Sequential(\n",
    "        nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.LazyBatchNorm2d(), \n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "    net.add_module(\"resnet_block1\", resnet_block(64, 2, first_block=True))\n",
    "    net.add_module(\"resnet_block2\", resnet_block(128, 2))\n",
    "    net.add_module(\"resnet_block3\", resnet_block(256, 2))\n",
    "    net.add_module(\"resnet_block4\", resnet_block(512, 2))\n",
    "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
    "    net.add_module(\"fc\", nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.LazyLinear(num_classes)\n",
    "    ))\n",
    "    return net\n",
    "\n",
    "def use_svg_display():\n",
    "    \"\"\"使用svg格式显示绘图\"\"\"\n",
    "    from matplotlib_inline import backend_inline\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    \"\"\"Set the figure size for matplotlib.\"\"\"\n",
    "    use_svg_display()\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        # 将tensor或PIL图像转换为numpy数组\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            # 如果是PyTorch tensor，转换为numpy\n",
    "            img = img.detach().cpu().numpy()\n",
    "            # 如果是(C, H, W)格式，转换为(H, W, C)\n",
    "            if img.ndim == 3 and img.shape[0] in [1, 3]:\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "            # 如果是单通道图像，去掉通道维度\n",
    "            if img.shape[-1] == 1:\n",
    "                img = img.squeeze(-1)\n",
    "        ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes\n",
    "\n",
    "\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "\n",
    "def download(name, cache_dir='../data'):\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 DATA_HUB\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    \n",
    "    # 如果文件已存在且哈希值匹配，直接返回\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    \n",
    "    # 下载文件\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "\n",
    "def download_extract(name, folder=None):\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    \n",
    "    if ext == '.zip':\n",
    "        with zipfile.ZipFile(fname, 'r') as fp:\n",
    "            fp.extractall(base_dir)\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        import tarfile\n",
    "        with tarfile.open(fname, 'r') as fp:\n",
    "            fp.extractall(base_dir)\n",
    "    \n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "\n",
    "def train_batch_ch13(net, X, y, loss, trainer, devices):\n",
    "    \"\"\"用多GPU进行小批量训练\"\"\"\n",
    "    if isinstance(X, list):\n",
    "        # 对于BERT微调所需的\n",
    "        X = [x.to(devices[0]) for x in X]\n",
    "    else:\n",
    "        X = X.to(devices[0])\n",
    "    y = y.to(devices[0])\n",
    "    \n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    pred = net(X)\n",
    "    l = loss(pred, y)\n",
    "    l.mean().backward()  # 使用mean而不是sum，这样梯度更稳定\n",
    "    trainer.step()\n",
    "    \n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum\n",
    "\n",
    "\n",
    "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices=None):\n",
    "    \"\"\"用GPU训练模型（在第十三章定义）\"\"\"\n",
    "    if devices is None:\n",
    "        devices = try_all_gpus()\n",
    "    \n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
    "                       legend=['train loss', 'train acc', 'test acc'])\n",
    "    \n",
    "    # 只有在有多个GPU时才使用DataParallel\n",
    "    if len(devices) > 1 and str(devices[0]).startswith('cuda'):\n",
    "        net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    else:\n",
    "        net = net.to(devices[0])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和，训练准确率之和，样本数\n",
    "        metric = Accumulator(3)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = train_batch_ch13(net, features, labels, loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0])\n",
    "            timer.stop()\n",
    "            \n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                           (metric[0] / metric[2], metric[1] / metric[2], None))\n",
    "        \n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    \n",
    "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
    "          f'{metric[1] / metric[2]:.3f}, test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB['hotdog'] = (DATA_URL + 'hotdog.zip', 'fba480ffa8aa7e0febbb511d181409f899b9baa5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = download_extract('hotdog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2334132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))\n",
    "test_images = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d713516",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_dogs = [train_images[i][0] for i in range(8)]\n",
    "not_hot_dogs = [train_images[-i-1][0] for i in range(8)]\n",
    "show_images(hot_dogs + not_hot_dogs, 2, 8, scale=1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae0a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般预测时是不会“反向”做回去的。模型训练和预测阶段都用相同的归一化（标准化）操作，即\n",
    "# transforms.ToTensor() 归一化到 0~1，transforms.Normalize(...) 做标准化。\n",
    "# 如果你想让模型输出的人眼可读（比如用plt.imshow显示图片），可以用反归一化，把标准化步骤的操作反着来：\n",
    "# img = img * std + mean， 记得要先把Tensor数据恢复成numpy类型，数值范围也要限制在0~1或0~255。\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406],  # 这三个数字分别是归一化到0~1后R、G、B通道的均值\n",
    "    [0.229, 0.224, 0.225]   # 这三个数字分别是归一化到0~1后R、G、B通道的标准差\n",
    ")\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    # 这里用的是RandomResizedCrop(224)，意思是在原图上随机裁剪出一块区域，然后再resize到224x224。为什么是“随机”的裁剪呢？因为这样可以让模型看到目标在不同位置、尺度、比例的情况，相当于一种数据增强，能提升模型对输入变换的鲁棒性（比如现实中拍照时热狗可能大可能小，可能在左侧可能在右侧）。如果总是同一个位置同样resize，训练出来的模型泛化能力就差了。\n",
    "    # 另外随机裁剪有可能裁出来的那块区域不包含全部目标，甚至全是背景，也有助于让模型学会区分重要特征和干扰特征。\n",
    "    # 那是不是有的图像其实没 resize 呢？实际上RandomResizedCrop会先随机选个区域（有大小和宽高比限制），然后无论原来这块有多大都强行resize为224×224送进网络，所以所有图片的尺寸最终都会统一为224×224，但内容的可视范围和内容比例是随机的。\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(255),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6286f93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yw.hao/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/yw.hao/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/yw.hao/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "pretrain_net = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pretrain_net.fc:\", pretrain_net.fc)\n",
    "print(\"ResNet18属性:\")\n",
    "print(list(pretrain_net.named_children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecacf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yw.hao/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/yw.hao/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /Users/yw.hao/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
      "0.5%"
     ]
    }
   ],
   "source": [
    "finetune_net = torchvision.models.resnet18(pretrained=True)\n",
    "finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True):\n",
    "    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=train_augs\n",
    "    ), batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'test'), transform=test_augs\n",
    "    ), batch_size=batch_size)\n",
    "    devices = try_all_gpus()\n",
    "    loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters() if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        trainer = torch.optim.SGD([\n",
    "            {'params': params_1x},\n",
    "            {'params': net.fc.parameters(), \"lr\": learning_rate * 10}\n",
    "        ], lr=learning_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "    train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fine_tuning(finetune_net, learning_rate=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_res18 = torchvision.models.resnet18()\n",
    "scratch_res18.fc = nn.Linear(scratch_res18.fc.in_features, 2)\n",
    "train_fine_tuning(scratch_res18, 5e-4, param_group=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
