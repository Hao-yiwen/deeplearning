{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ff15a7",
   "metadata": {},
   "source": [
    "# æ ‘å¶åˆ†ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6622e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil  # shutilåº“ç”¨äºæ–‡ä»¶å’Œæ–‡ä»¶å¤¹çš„é«˜çº§æ“ä½œï¼Œä¾‹å¦‚å¤åˆ¶ã€ç§»åŠ¨ã€åˆ é™¤ç­‰\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import hashlib\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831626a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–æ•°æ®å¹¶æŸ¥çœ‹ç±»åˆ«\n",
    "data_dir = './classify-leaves'\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "print(f'è®­ç»ƒé›†å¤§å°: {len(train_df)}')\n",
    "print(f'æµ‹è¯•é›†å¤§å°: {len(test_df)}')\n",
    "print(f'\\nè®­ç»ƒé›†å‰å‡ è¡Œ:')\n",
    "print(train_df.head())\n",
    "\n",
    "# è·å–æ‰€æœ‰ç±»åˆ«\n",
    "labels = train_df['label'].unique()\n",
    "num_classes = len(labels)\n",
    "print(f'\\nç±»åˆ«æ•°é‡: {num_classes}')\n",
    "print(f'éƒ¨åˆ†ç±»åˆ«: {labels[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3vw84v50qii",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ ‡ç­¾åˆ°ç´¢å¼•çš„æ˜ å°„\n",
    "label_to_idx = {label: idx for idx, label in enumerate(sorted(labels))}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "print(f'æ ‡ç­¾æ˜ å°„ç¤ºä¾‹:')\n",
    "for i, (label, idx) in enumerate(list(label_to_idx.items())[:5]):\n",
    "    print(f'{label} -> {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qqt7q36qzq8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå®šä¹‰æ•°æ®é›†ç±»\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class LeavesDataset(Dataset):\n",
    "    \"\"\"æ ‘å¶åˆ†ç±»æ•°æ®é›†\"\"\"\n",
    "    def __init__(self, csv_file, root_dir, label_to_idx=None, transform=None, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): CSVæ–‡ä»¶è·¯å¾„\n",
    "            root_dir (string): æ•°æ®æ ¹ç›®å½•\n",
    "            label_to_idx (dict): æ ‡ç­¾åˆ°ç´¢å¼•çš„æ˜ å°„\n",
    "            transform (callable, optional): æ•°æ®å˜æ¢\n",
    "            is_test (bool): æ˜¯å¦ä¸ºæµ‹è¯•é›†\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.label_to_idx = label_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # è·å–å›¾ç‰‡è·¯å¾„\n",
    "        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            # æµ‹è¯•é›†åªè¿”å›å›¾ç‰‡\n",
    "            return image\n",
    "        else:\n",
    "            # è®­ç»ƒé›†è¿”å›å›¾ç‰‡å’Œæ ‡ç­¾\n",
    "            label = self.data_frame.iloc[idx, 1]\n",
    "            label_idx = self.label_to_idx[label]\n",
    "            return image, label_idx\n",
    "\n",
    "print('æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j5v1ev4w8nl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å¢å¼ºå’Œé¢„å¤„ç†ï¼ˆå¢å¼ºç‰ˆï¼‰\n",
    "from torchvision import transforms\n",
    "\n",
    "# è®­ç»ƒé›†æ•°æ®å¢å¼º - é€‚åº¦å¢å¼º\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # éšæœºè£å‰ªå¹¶è°ƒæ•´å¤§å°\n",
    "    transforms.RandomHorizontalFlip(),  # éšæœºæ°´å¹³ç¿»è½¬\n",
    "    transforms.RandomVerticalFlip(p=0.3),  # éšæœºå‚ç›´ç¿»è½¬\n",
    "    transforms.RandomRotation(30),  # å¢åŠ æ—‹è½¬è§’åº¦åˆ°30åº¦\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),  # å¢å¼ºé¢œè‰²æŠ–åŠ¨\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNetæ ‡å‡†åŒ–\n",
    "])\n",
    "\n",
    "# éªŒè¯é›†/æµ‹è¯•é›†æ•°æ®é¢„å¤„ç†ï¼ˆä¸åšæ•°æ®å¢å¼ºï¼‰\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print('æ•°æ®å¢å¼ºè®¾ç½®å®Œæˆ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lq1i453nbhb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# å°†è®­ç»ƒæ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ80%è®­ç»ƒï¼Œ20%éªŒè¯ï¼‰\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "# ä¿å­˜ä¸ºä¸´æ—¶CSVæ–‡ä»¶\n",
    "train_csv_path = os.path.join(data_dir, 'train_split.csv')\n",
    "val_csv_path = os.path.join(data_dir, 'val_split.csv')\n",
    "train_data.to_csv(train_csv_path, index=False)\n",
    "val_data.to_csv(val_csv_path, index=False)\n",
    "\n",
    "print(f'è®­ç»ƒé›†å¤§å°: {len(train_data)}')\n",
    "print(f'éªŒè¯é›†å¤§å°: {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n0hdb0ejq9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨\n",
    "batch_size = 32\n",
    "\n",
    "# è®­ç»ƒæ•°æ®é›†\n",
    "train_dataset = LeavesDataset(\n",
    "    csv_file=train_csv_path,\n",
    "    root_dir=data_dir,\n",
    "    label_to_idx=label_to_idx,\n",
    "    transform=train_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# éªŒè¯æ•°æ®é›†\n",
    "val_dataset = LeavesDataset(\n",
    "    csv_file=val_csv_path,\n",
    "    root_dir=data_dir,\n",
    "    label_to_idx=label_to_idx,\n",
    "    transform=val_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# æµ‹è¯•æ•°æ®é›†\n",
    "test_dataset = LeavesDataset(\n",
    "    csv_file=os.path.join(data_dir, 'test.csv'),\n",
    "    root_dir=data_dir,\n",
    "    label_to_idx=label_to_idx,\n",
    "    transform=val_transform,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "# æ•°æ®åŠ è½½å™¨\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f'è®­ç»ƒé›†æ‰¹æ¬¡æ•°: {len(train_loader)}')\n",
    "print(f'éªŒè¯é›†æ‰¹æ¬¡æ•°: {len(val_loader)}')\n",
    "print(f'æµ‹è¯•é›†æ‰¹æ¬¡æ•°: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6mu0n2s9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUè®¾å¤‡å‡½æ•°\n",
    "def try_gpu(i=0):\n",
    "    \"\"\"è¿”å›ç¬¬iä¸ªGPUè®¾å¤‡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›CPU\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "print(f'å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51p5rn64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æ¨¡å‹ - ä½¿ç”¨ResNet34ä»å¤´è®­ç»ƒ\n",
    "import torchvision.models as models\n",
    "\n",
    "def get_model(num_classes, model_name='resnet34', pretrained=False):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºResNetæ¨¡å‹\n",
    "    Args:\n",
    "        num_classes: ç±»åˆ«æ•°é‡\n",
    "        model_name: æ¨¡å‹åç§° ('resnet18', 'resnet34', 'resnet50')\n",
    "        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆä»å¤´è®­ç»ƒè®¾ä¸ºFalseï¼‰\n",
    "    \"\"\"\n",
    "    # åŠ è½½æŒ‡å®šçš„ResNetæ¨¡å‹\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "    elif model_name == 'resnet34':\n",
    "        model = models.resnet34(pretrained=pretrained)\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "    else:\n",
    "        raise ValueError(f'ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}')\n",
    "    \n",
    "    # ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚ä»¥é€‚åº”æˆ‘ä»¬çš„ç±»åˆ«æ•°é‡\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨ResNet34ä»å¤´è®­ç»ƒ\n",
    "device = try_gpu()\n",
    "net = get_model(num_classes=num_classes, model_name='resnet50', pretrained=False)\n",
    "net = net.to(device)\n",
    "\n",
    "print(f'ä½¿ç”¨è®¾å¤‡: {device}')\n",
    "print(f'æ¨¡å‹: ResNet-34 (ä»å¤´è®­ç»ƒ)')\n",
    "print(f'æ¨¡å‹ç±»åˆ«æ•°: {num_classes}')\n",
    "print(f'æ¨¡å‹æœ€åä¸€å±‚: {net.fc}')\n",
    "\n",
    "# ç»Ÿè®¡æ¨¡å‹å‚æ•°\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f'\\næ€»å‚æ•°é‡: {total_params:,}')\n",
    "print(f'å¯è®­ç»ƒå‚æ•°: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecxdv5yhjqf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰è®­ç»ƒå‡½æ•°\n",
    "def train_epoch(net, train_loader, loss_fn, optimizer, device):\n",
    "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        outputs = net(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # åå‘ä¼ æ’­å’Œä¼˜åŒ–\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_acc += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # æ‰“å°è¿›åº¦\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print(f'  Batch [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'Loss: {loss.item():.4f}, '\n",
    "                  f'Acc: {100. * predicted.eq(labels).sum().item() / labels.size(0):.2f}%')\n",
    "    \n",
    "    return train_loss / total, train_acc / total\n",
    "\n",
    "\n",
    "def validate(net, val_loader, loss_fn, device):\n",
    "    \"\"\"éªŒè¯å‡½æ•°\"\"\"\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = net(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_acc += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return val_loss / total, val_acc / total\n",
    "\n",
    "print('è®­ç»ƒå’ŒéªŒè¯å‡½æ•°å®šä¹‰å®Œæˆ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xu23o4z0ktb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eiq2tchkzf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒé…ç½®ï¼ˆä»å¤´è®­ç»ƒResNet-34 + AdamW + ä½™å¼¦é€€ç«ï¼‰\n",
    "num_epochs = 50  # ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šepochs\n",
    "learning_rate = 1e-3  # AdamWæ¨èçš„å­¦ä¹ ç‡\n",
    "weight_decay = 0.05  # AdamWæ¨èæ›´å¤§çš„weight_decay\n",
    "min_lr = 1e-6  # æœ€å°å­¦ä¹ ç‡\n",
    "\n",
    "# æŸå¤±å‡½æ•°\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# ä¼˜åŒ–å™¨ - ä½¿ç”¨AdamWï¼ˆä»å¤´è®­ç»ƒæ•ˆæœå¥½ï¼Œæ”¶æ•›å¿«ï¼‰\n",
    "optimizer = torch.optim.AdamW(\n",
    "    net.parameters(), \n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.999),  # Adamçš„é»˜è®¤å€¼\n",
    "    weight_decay=weight_decay  # AdamWè§£è€¦çš„weight decay\n",
    ")\n",
    "\n",
    "# å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½™å¼¦é€€ç«ï¼ˆä¸AdamWæ­é…æ•ˆæœå¥½ï¼‰\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=num_epochs,  # ä½™å¼¦å‘¨æœŸ\n",
    "    eta_min=min_lr     # æœ€å°å­¦ä¹ ç‡\n",
    ")\n",
    "\n",
    "print(f'è®­ç»ƒé…ç½®:')\n",
    "print(f'  æ¨¡å‹: ResNet-34 (ä»å¤´è®­ç»ƒ)')\n",
    "print(f'  Epochs: {num_epochs}')\n",
    "print(f'  åˆå§‹å­¦ä¹ ç‡: {learning_rate}')\n",
    "print(f'  æœ€å°å­¦ä¹ ç‡: {min_lr}')\n",
    "print(f'  ä¼˜åŒ–å™¨: AdamW â­')\n",
    "print(f'  Weight Decay: {weight_decay} (AdamWè§£è€¦)')\n",
    "print(f'  è°ƒåº¦å™¨: CosineAnnealingLR (T_max={num_epochs})')\n",
    "print(f'\\nAdamW + ä½™å¼¦é€€ç«ä¼˜åŠ¿ï¼š')\n",
    "print(f'  âœ“ æ”¶æ•›é€Ÿåº¦å¿«ï¼Œé€‚åˆä»å¤´è®­ç»ƒ')\n",
    "print(f'  âœ“ è‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œå¯¹è¶…å‚æ•°ä¸æ•æ„Ÿ')\n",
    "print(f'  âœ“ Weight decayè§£è€¦ï¼Œæ­£åˆ™åŒ–æ•ˆæœæ›´å¥½')\n",
    "print(f'  âœ“ ä¸ä½™å¼¦é€€ç«æ­é…ï¼Œå­¦ä¹ ç‡å¹³æ»‘ä¸‹é™')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlou8y7585m",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcngo0noo4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸»è®­ç»ƒå¾ªç¯\n",
    "best_val_acc = 0.0\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []  # æ·»åŠ å­¦ä¹ ç‡è®°å½•\n",
    "}\n",
    "\n",
    "print('å¼€å§‹è®­ç»ƒ...\\n')\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 60)\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    train_loss, train_acc = train_epoch(net, train_loader, loss_fn, optimizer, device)\n",
    "    \n",
    "    # éªŒè¯\n",
    "    val_loss, val_acc = validate(net, val_loader, loss_fn, device)\n",
    "    \n",
    "    # è®°å½•å½“å‰å­¦ä¹ ç‡\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # æ›´æ–°å­¦ä¹ ç‡\n",
    "    scheduler.step()\n",
    "    \n",
    "    # è®°å½•å†å²\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # æ‰“å°ç»“æœ\n",
    "    print(f'\\nè®­ç»ƒé›† - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}')\n",
    "    print(f'éªŒè¯é›† - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}')\n",
    "    print(f'å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}')\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(net.state_dict(), 'best_model.pth')\n",
    "        print(f'âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f})')\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f'\\nè®­ç»ƒå®Œæˆï¼')\n",
    "print(f'æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f6b1d9pp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è®­ç»ƒå†å²ï¼ˆåŒ…å«ä½™å¼¦é€€ç«å­¦ä¹ ç‡æ›²çº¿ï¼‰\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# æŸå¤±æ›²çº¿\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# å‡†ç¡®ç‡æ›²çº¿\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# å­¦ä¹ ç‡æ›²çº¿ï¼ˆä½™å¼¦é€€ç«ï¼‰\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['lr'], label='Learning Rate', color='orange', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Cosine Annealing LR Schedule')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦æ›´æ¸…æ™°\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('è®­ç»ƒå†å²å·²ä¿å­˜ä¸º training_history.png')\n",
    "print(f'\\nè®­ç»ƒç»Ÿè®¡:')\n",
    "print(f'æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(history[\"val_acc\"]):.4f} (Epoch {history[\"val_acc\"].index(max(history[\"val_acc\"]))+1})')\n",
    "print(f'æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {history[\"train_acc\"][-1]:.4f}')\n",
    "print(f'æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {history[\"val_acc\"][-1]:.4f}')\n",
    "print(f'\\nå­¦ä¹ ç‡å˜åŒ–:')\n",
    "print(f'åˆå§‹å­¦ä¹ ç‡: {history[\"lr\"][0]:.6f}')\n",
    "print(f'æœ€ç»ˆå­¦ä¹ ç‡: {history[\"lr\"][-1]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sw2atlarpg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "net.load_state_dict(torch.load('best_model.pth'))\n",
    "net.eval()\n",
    "\n",
    "print('ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹...\\n')\n",
    "\n",
    "# é¢„æµ‹æµ‹è¯•é›†\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(f'é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} ä¸ªæ ·æœ¬')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5m9n050e8jq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæäº¤æ–‡ä»¶\n",
    "# å°†é¢„æµ‹çš„ç´¢å¼•è½¬æ¢å›æ ‡ç­¾åç§°\n",
    "predicted_labels = [idx_to_label[idx] for idx in predictions]\n",
    "\n",
    "# åˆ›å»ºæäº¤DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'image': test_df['image'],\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "# ä¿å­˜æäº¤æ–‡ä»¶\n",
    "submission_path = 'submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f'æäº¤æ–‡ä»¶å·²ä¿å­˜ä¸º: {submission_path}')\n",
    "print(f'\\næäº¤æ–‡ä»¶å‰å‡ è¡Œ:')\n",
    "print(submission.head(10))\n",
    "print(f'\\næäº¤æ–‡ä»¶ç»Ÿè®¡:')\n",
    "print(f'æ€»æ ·æœ¬æ•°: {len(submission)}')\n",
    "print(f'é¢„æµ‹çš„å”¯ä¸€ç±»åˆ«æ•°: {submission[\"label\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eamfx8jutqj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (å¯é€‰) å¯è§†åŒ–ä¸€äº›éªŒè¯é›†é¢„æµ‹ç»“æœ\n",
    "def visualize_predictions(net, val_loader, device, num_images=8):\n",
    "    \"\"\"å¯è§†åŒ–ä¸€äº›é¢„æµ‹ç»“æœ\"\"\"\n",
    "    net.eval()\n",
    "    images_shown = 0\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images_batch = images.to(device)\n",
    "            outputs = net(images_batch)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                \n",
    "                # åå½’ä¸€åŒ–å›¾ç‰‡ç”¨äºæ˜¾ç¤º\n",
    "                img = images[i].cpu().numpy()\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                \n",
    "                # æ˜¾ç¤ºå›¾ç‰‡\n",
    "                axes[images_shown].imshow(img)\n",
    "                axes[images_shown].axis('off')\n",
    "                \n",
    "                # è®¾ç½®æ ‡é¢˜\n",
    "                true_label = idx_to_label[labels[i].item()]\n",
    "                pred_label = idx_to_label[predicted[i].item()]\n",
    "                color = 'green' if true_label == pred_label else 'red'\n",
    "                axes[images_shown].set_title(\n",
    "                    f'True: {true_label[:15]}\\nPred: {pred_label[:15]}',\n",
    "                    fontsize=10,\n",
    "                    color=color\n",
    "                )\n",
    "                \n",
    "                images_shown += 1\n",
    "            \n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('predictions_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'é¢„æµ‹ç»“æœå¯è§†åŒ–å·²ä¿å­˜ä¸º predictions_visualization.png')\n",
    "\n",
    "# å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
    "visualize_predictions(net, val_loader, device, num_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tr9wqnqtt6d",
   "metadata": {},
   "source": [
    "## è®­ç»ƒæ€»ç»“\n",
    "\n",
    "æœ¬notebookå®ç°äº†æ ‘å¶åˆ†ç±»çš„å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆä»å¤´è®­ç»ƒResNet-34 + AdamW + ä½™å¼¦é€€ç«ï¼‰ï¼š\n",
    "\n",
    "### 1. æ•°æ®å¤„ç†\n",
    "- è®­ç»ƒé›†ï¼š18,353å¼ å›¾ç‰‡\n",
    "- æµ‹è¯•é›†ï¼š8,800å¼ å›¾ç‰‡  \n",
    "- æ•°æ®åˆ’åˆ†ï¼š80%è®­ç»ƒï¼Œ20%éªŒè¯\n",
    "- **å¢å¼ºæ•°æ®å¢å¼º**ï¼š\n",
    "  - RandomResizedCrop\n",
    "  - RandomHorizontalFlip + RandomVerticalFlip\n",
    "  - RandomRotation (30Â°)\n",
    "  - ColorJitterï¼ˆå¢å¼ºç‰ˆï¼‰\n",
    "\n",
    "### 2. æ¨¡å‹æ¶æ„\n",
    "- **ResNet-34**ï¼ˆä»å¤´è®­ç»ƒï¼Œä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼‰\n",
    "- å‚æ•°é‡ï¼šçº¦21.8M\n",
    "- è¾“å‡ºå±‚ï¼šæ ¹æ®å®é™…ç±»åˆ«æ•°é‡è°ƒæ•´\n",
    "\n",
    "### 3. è®­ç»ƒé…ç½® â­\n",
    "- **ä¼˜åŒ–å™¨**: **AdamW**ï¼ˆæ¯”SGDæ”¶æ•›æ›´å¿«ï¼‰\n",
    "- **åˆå§‹å­¦ä¹ ç‡**: 1e-3ï¼ˆAdamWæ¨èå€¼ï¼‰\n",
    "- **æœ€å°å­¦ä¹ ç‡**: 1e-6\n",
    "- **Weight Decay**: 0.05ï¼ˆAdamWè§£è€¦çš„weight decayï¼‰\n",
    "- **å­¦ä¹ ç‡è°ƒåº¦**: **CosineAnnealingLR**\n",
    "- **æŸå¤±å‡½æ•°**: CrossEntropyLoss\n",
    "- **Batch size**: 32\n",
    "- **Epochs**: 50\n",
    "\n",
    "### 4. AdamW + ä½™å¼¦é€€ç«ç»„åˆä¼˜åŠ¿ ğŸš€\n",
    "1. **å¿«é€Ÿæ”¶æ•›**ï¼š\n",
    "   - AdamWè‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œå‰æœŸæ”¶æ•›é€Ÿåº¦æ¯”SGDå¿«2-3å€\n",
    "   - å¯ä»¥æ›´æ—©çœ‹åˆ°è®­ç»ƒæ•ˆæœ\n",
    "   \n",
    "2. **æ˜“äºè°ƒå‚**ï¼š\n",
    "   - å¯¹å­¦ä¹ ç‡åˆå§‹å€¼ä¸æ•æ„Ÿ\n",
    "   - Weight decayæ¨èèŒƒå›´ï¼š0.01-0.1\n",
    "   - å­¦ä¹ ç‡æ¨èèŒƒå›´ï¼š1e-4 åˆ° 1e-3\n",
    "\n",
    "3. **Weight Decayè§£è€¦**ï¼š\n",
    "   - AdamWå°†weight decayä»æ¢¯åº¦æ›´æ–°ä¸­è§£è€¦\n",
    "   - æ­£åˆ™åŒ–æ•ˆæœæ›´ç¨³å®šã€æ›´å¥½\n",
    "\n",
    "4. **å®Œç¾æ­é…ä½™å¼¦é€€ç«**ï¼š\n",
    "   - AdamW + CosineAnnealingLR è¢«è¯æ˜æ˜¯SOTAé…ç½®\n",
    "   - åœ¨Vision Transformerç­‰ç°ä»£æ¶æ„ä¸­å¹¿æ³›ä½¿ç”¨\n",
    "\n",
    "### 5. å­¦ä¹ ç‡å˜åŒ–\n",
    "```\n",
    "lr = 1e-3 * (1 + cos(Ï€ * epoch / 50)) / 2 + 1e-6\n",
    "\n",
    "Epoch 0:  lr = 0.001      (æœ€é«˜)\n",
    "Epoch 12: lr â‰ˆ 0.0005     (ä¸‹é™50%)\n",
    "Epoch 25: lr â‰ˆ 0.0001     (ä¸‹é™90%)\n",
    "Epoch 37: lr â‰ˆ 0.00002\n",
    "Epoch 50: lr = 0.000001   (æœ€å°)\n",
    "```\n",
    "\n",
    "### 6. é¢„æœŸæ•ˆæœ\n",
    "- **æ”¶æ•›é€Ÿåº¦**ï¼šå‰10ä¸ªepochå°±èƒ½çœ‹åˆ°æ˜æ˜¾æ•ˆæœ\n",
    "- **æœ€ç»ˆç²¾åº¦**ï¼šä¸SGDç›¸å½“æˆ–æ›´å¥½ï¼ˆä»å¤´è®­ç»ƒåœºæ™¯ï¼‰\n",
    "- **è®­ç»ƒç¨³å®šæ€§**ï¼šæ›´ç¨³å®šï¼Œä¸å®¹æ˜“å‡ºç°loss spike\n",
    "\n",
    "### 7. è¾“å‡ºæ–‡ä»¶\n",
    "- `best_model.pth`: æœ€ä½³æ¨¡å‹æƒé‡\n",
    "- `submission.csv`: Kaggleæäº¤æ–‡ä»¶\n",
    "- `training_history.png`: è®­ç»ƒå†å²æ›²çº¿ï¼ˆåŒ…å«ä½™å¼¦é€€ç«æ›²çº¿ï¼‰\n",
    "- `predictions_visualization.png`: é¢„æµ‹ç»“æœå¯è§†åŒ–"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
