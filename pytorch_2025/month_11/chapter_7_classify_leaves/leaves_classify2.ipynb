{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ff15a7",
   "metadata": {},
   "source": [
    "# 树叶分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6622e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil  # shutil库用于文件和文件夹的高级操作，例如复制、移动、删除等\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import hashlib\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831626a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据并查看类别\n",
    "data_dir = './classify-leaves'\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "print(f'训练集大小: {len(train_df)}')\n",
    "print(f'测试集大小: {len(test_df)}')\n",
    "print(f'\\n训练集前几行:')\n",
    "print(train_df.head())\n",
    "\n",
    "# 获取所有类别\n",
    "labels = train_df['label'].unique()\n",
    "num_classes = len(labels)\n",
    "print(f'\\n类别数量: {num_classes}')\n",
    "print(f'部分类别: {labels[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3vw84v50qii",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建标签到索引的映射\n",
    "label_to_idx = {label: idx for idx, label in enumerate(sorted(labels))}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "print(f'标签映射示例:')\n",
    "for i, (label, idx) in enumerate(list(label_to_idx.items())[:5]):\n",
    "    print(f'{label} -> {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qqt7q36qzq8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class LeavesDataset(Dataset):\n",
    "    \"\"\"树叶分类数据集\"\"\"\n",
    "    def __init__(self, csv_file, root_dir, label_to_idx=None, transform=None, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): CSV文件路径\n",
    "            root_dir (string): 数据根目录\n",
    "            label_to_idx (dict): 标签到索引的映射\n",
    "            transform (callable, optional): 数据变换\n",
    "            is_test (bool): 是否为测试集\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.label_to_idx = label_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # 获取图片路径\n",
    "        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            # 测试集只返回图片\n",
    "            return image\n",
    "        else:\n",
    "            # 训练集返回图片和标签\n",
    "            label = self.data_frame.iloc[idx, 1]\n",
    "            label_idx = self.label_to_idx[label]\n",
    "            return image, label_idx\n",
    "\n",
    "print('数据集类定义完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j5v1ev4w8nl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强和预处理（增强版）\n",
    "from torchvision import transforms\n",
    "\n",
    "# 训练集数据增强 - 适度增强\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # 随机裁剪并调整大小\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomVerticalFlip(p=0.3),  # 随机垂直翻转\n",
    "    transforms.RandomRotation(30),  # 增加旋转角度到30度\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),  # 增强颜色抖动\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "\n",
    "# 验证集/测试集数据预处理（不做数据增强）\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print('数据增强设置完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lq1i453nbhb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 将训练数据划分为训练集和验证集（80%训练，20%验证）\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "# 保存为临时CSV文件\n",
    "train_csv_path = os.path.join(data_dir, 'train_split.csv')\n",
    "val_csv_path = os.path.join(data_dir, 'val_split.csv')\n",
    "train_data.to_csv(train_csv_path, index=False)\n",
    "val_data.to_csv(val_csv_path, index=False)\n",
    "\n",
    "print(f'训练集大小: {len(train_data)}')\n",
    "print(f'验证集大小: {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n0hdb0ejq9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集和数据加载器\n",
    "batch_size = 32\n",
    "\n",
    "# 训练数据集\n",
    "train_dataset = LeavesDataset(\n",
    "    csv_file=train_csv_path,\n",
    "    root_dir=data_dir,\n",
    "    label_to_idx=label_to_idx,\n",
    "    transform=train_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# 验证数据集\n",
    "val_dataset = LeavesDataset(\n",
    "    csv_file=val_csv_path,\n",
    "    root_dir=data_dir,\n",
    "    label_to_idx=label_to_idx,\n",
    "    transform=val_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# 测试数据集\n",
    "test_dataset = LeavesDataset(\n",
    "    csv_file=os.path.join(data_dir, 'test.csv'),\n",
    "    root_dir=data_dir,\n",
    "    label_to_idx=label_to_idx,\n",
    "    transform=val_transform,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f'训练集批次数: {len(train_loader)}')\n",
    "print(f'验证集批次数: {len(val_loader)}')\n",
    "print(f'测试集批次数: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6mu0n2s9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU设备函数\n",
    "def try_gpu(i=0):\n",
    "    \"\"\"返回第i个GPU设备，如果不存在则返回CPU\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "print(f'可用GPU数量: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51p5rn64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型 - 使用ResNet34从头训练\n",
    "import torchvision.models as models\n",
    "\n",
    "def get_model(num_classes, model_name='resnet34', pretrained=False):\n",
    "    \"\"\"\n",
    "    创建ResNet模型\n",
    "    Args:\n",
    "        num_classes: 类别数量\n",
    "        model_name: 模型名称 ('resnet18', 'resnet34', 'resnet50')\n",
    "        pretrained: 是否使用预训练权重（从头训练设为False）\n",
    "    \"\"\"\n",
    "    # 加载指定的ResNet模型\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "    elif model_name == 'resnet34':\n",
    "        model = models.resnet34(pretrained=pretrained)\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "    else:\n",
    "        raise ValueError(f'不支持的模型: {model_name}')\n",
    "    \n",
    "    # 修改最后的全连接层以适应我们的类别数量\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 创建模型 - 使用ResNet34从头训练\n",
    "device = try_gpu()\n",
    "net = get_model(num_classes=num_classes, model_name='resnet34', pretrained=False)\n",
    "net = net.to(device)\n",
    "\n",
    "print(f'使用设备: {device}')\n",
    "print(f'模型: ResNet-34 (从头训练)')\n",
    "print(f'模型类别数: {num_classes}')\n",
    "print(f'模型最后一层: {net.fc}')\n",
    "\n",
    "# 统计模型参数\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f'\\n总参数量: {total_params:,}')\n",
    "print(f'可训练参数: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecxdv5yhjqf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train_epoch(net, train_loader, loss_fn, optimizer, device):\n",
    "    \"\"\"训练一个epoch\"\"\"\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = net(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 统计\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_acc += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # 打印进度\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print(f'  Batch [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'Loss: {loss.item():.4f}, '\n",
    "                  f'Acc: {100. * predicted.eq(labels).sum().item() / labels.size(0):.2f}%')\n",
    "    \n",
    "    return train_loss / total, train_acc / total\n",
    "\n",
    "\n",
    "def validate(net, val_loader, loss_fn, device):\n",
    "    \"\"\"验证函数\"\"\"\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = net(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_acc += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return val_loss / total, val_acc / total\n",
    "\n",
    "print('训练和验证函数定义完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xu23o4z0ktb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eiq2tchkzf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置（从头训练ResNet-34）\n",
    "num_epochs = 50  # 从头训练需要更多epochs\n",
    "learning_rate = 0.01  # 从头训练使用较大的学习率\n",
    "weight_decay = 5e-4  # L2正则化\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器 - 使用SGD with momentum（从头训练通常效果更好）\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), \n",
    "    lr=learning_rate,\n",
    "    momentum=0.9,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "# 学习率调度器 - StepLR（每15个epoch降低学习率）\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "\n",
    "print(f'训练配置:')\n",
    "print(f'  模型: ResNet-34 (从头训练)')\n",
    "print(f'  Epochs: {num_epochs}')\n",
    "print(f'  Learning Rate: {learning_rate}')\n",
    "print(f'  Optimizer: SGD with Momentum (0.9)')\n",
    "print(f'  Weight Decay: {weight_decay}')\n",
    "print(f'  Scheduler: StepLR (step_size=15, gamma=0.1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlou8y7585m",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcngo0noo4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主训练循环\n",
    "best_val_acc = 0.0\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print('开始训练...\\n')\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 60)\n",
    "    \n",
    "    # 训练\n",
    "    train_loss, train_acc = train_epoch(net, train_loader, loss_fn, optimizer, device)\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_acc = validate(net, val_loader, loss_fn, device)\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f'\\n训练集 - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}')\n",
    "    print(f'验证集 - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}')\n",
    "    print(f'当前学习率: {scheduler.get_last_lr()[0]:.6f}')\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(net.state_dict(), 'best_model.pth')\n",
    "        print(f'✓ 保存最佳模型 (验证准确率: {val_acc:.4f})')\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f'\\n训练完成！')\n",
    "print(f'最佳验证准确率: {best_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f6b1d9pp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练历史\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 损失曲线\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 准确率曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('训练历史已保存为 training_history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sw2atlarpg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型进行预测\n",
    "net.load_state_dict(torch.load('best_model.pth'))\n",
    "net.eval()\n",
    "\n",
    "print('使用最佳模型进行预测...\\n')\n",
    "\n",
    "# 预测测试集\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(f'预测完成，共 {len(predictions)} 个样本')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5m9n050e8jq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "# 将预测的索引转换回标签名称\n",
    "predicted_labels = [idx_to_label[idx] for idx in predictions]\n",
    "\n",
    "# 创建提交DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'image': test_df['image'],\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "# 保存提交文件\n",
    "submission_path = 'submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f'提交文件已保存为: {submission_path}')\n",
    "print(f'\\n提交文件前几行:')\n",
    "print(submission.head(10))\n",
    "print(f'\\n提交文件统计:')\n",
    "print(f'总样本数: {len(submission)}')\n",
    "print(f'预测的唯一类别数: {submission[\"label\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eamfx8jutqj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (可选) 可视化一些验证集预测结果\n",
    "def visualize_predictions(net, val_loader, device, num_images=8):\n",
    "    \"\"\"可视化一些预测结果\"\"\"\n",
    "    net.eval()\n",
    "    images_shown = 0\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images_batch = images.to(device)\n",
    "            outputs = net(images_batch)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                \n",
    "                # 反归一化图片用于显示\n",
    "                img = images[i].cpu().numpy()\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                \n",
    "                # 显示图片\n",
    "                axes[images_shown].imshow(img)\n",
    "                axes[images_shown].axis('off')\n",
    "                \n",
    "                # 设置标题\n",
    "                true_label = idx_to_label[labels[i].item()]\n",
    "                pred_label = idx_to_label[predicted[i].item()]\n",
    "                color = 'green' if true_label == pred_label else 'red'\n",
    "                axes[images_shown].set_title(\n",
    "                    f'True: {true_label[:15]}\\nPred: {pred_label[:15]}',\n",
    "                    fontsize=10,\n",
    "                    color=color\n",
    "                )\n",
    "                \n",
    "                images_shown += 1\n",
    "            \n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('predictions_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'预测结果可视化已保存为 predictions_visualization.png')\n",
    "\n",
    "# 可视化预测结果\n",
    "visualize_predictions(net, val_loader, device, num_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tr9wqnqtt6d",
   "metadata": {},
   "source": [
    "## 训练总结\n",
    "\n",
    "本notebook实现了树叶分类的完整训练流程（从头训练ResNet-34）：\n",
    "\n",
    "### 1. 数据处理\n",
    "- 训练集：18,353张图片\n",
    "- 测试集：8,800张图片  \n",
    "- 数据划分：80%训练，20%验证\n",
    "- **增强数据增强**：\n",
    "  - RandomResizedCrop\n",
    "  - RandomHorizontalFlip + RandomVerticalFlip\n",
    "  - RandomRotation (30°)\n",
    "  - ColorJitter（增强版）\n",
    "\n",
    "### 2. 模型架构\n",
    "- **ResNet-34**（从头训练，不使用预训练权重）\n",
    "- 参数量：约21.8M\n",
    "- 输出层：根据实际类别数量调整\n",
    "\n",
    "### 3. 训练配置\n",
    "- **优化器**: SGD with Momentum (0.9)\n",
    "- **学习率**: 0.01（从头训练使用更大的初始学习率）\n",
    "- **Weight Decay**: 5e-4\n",
    "- **学习率调度**: StepLR (step_size=15, gamma=0.1)\n",
    "- **损失函数**: CrossEntropyLoss\n",
    "- **Batch size**: 32\n",
    "- **Epochs**: 50（从头训练需要更多epochs）\n",
    "\n",
    "### 4. 输出文件\n",
    "- `best_model.pth`: 最佳模型权重\n",
    "- `submission.csv`: Kaggle提交文件\n",
    "- `training_history.png`: 训练历史曲线\n",
    "- `predictions_visualization.png`: 预测结果可视化\n",
    "\n",
    "### 5. 优化亮点\n",
    "- 使用 ResNet-34 替代 ResNet-18，更强的特征提取能力\n",
    "- 从头训练而非微调，学习更适合树叶数据的特征\n",
    "- 增强的数据增强策略防止过拟合\n",
    "- SGD + Momentum 优化器对从头训练更友好\n",
    "- 更多的训练epochs以充分学习"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
